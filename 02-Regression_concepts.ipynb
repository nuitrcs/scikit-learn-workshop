{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "855e6e11-389a-4edb-9b32-eef018d04f17",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:rebeccapurple\">Setup</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f1237-f931-4272-aa29-d667d8a41631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b6a8dc-c696-4ec6-9c45-4513fc51cd43",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:rebeccapurple\">Supervised learning - Linear regression</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab524a3c-58b5-475e-acd2-8071f3912bd6",
   "metadata": {},
   "source": [
    "Linear regression model is typically\n",
    "$$\\begin{align}\n",
    "y = \\beta_0 + \\sum_{i=1}^N \\beta_i x_i\n",
    "\\end{align}$$\n",
    "where $y$ is the output, $x_i$ are the predictors and $N$ is the number of predictors. What we want to learn is the set of parameters, or weights, $\\beta_i, i=0,...N$.\n",
    "\n",
    "To learn these parameters, sklearn will minimize the residual sum of squares\n",
    "$$\n",
    "RSS = (y_{pred} - y_{obs})^2 = (\\beta_0 + \\sum_{i=1}^N \\beta_i x_i - y_{obs})^2\n",
    "$$\n",
    "where $M$ is the number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3313345f-8f8a-4915-b09d-8124f67f1145",
   "metadata": {},
   "source": [
    "### I. Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5325a-9e5c-4ee9-a3dd-696233f42216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a dataset\n",
    "df = pd.read_csv(\"data/fish.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7899a19d-b2e3-4210-a3ad-26e5dd30c39c",
   "metadata": {},
   "source": [
    "<h4><span style=\"color:blue\">Google Colab users only -- un-comment the code lines below and run them to download the dataset and read it</span></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562c2d80-0f35-4c94-8faa-7ae9d7dfd1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/nuitrcs/scikit-learn-workshop/main/data/fish.csv\n",
    "# df = pd.read_csv('fish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd493136-c9e1-479b-9ab7-0d6d454ddcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de972f-d483-4072-ab3f-7842a47336cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "sns.histplot(df.weight, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3318e5d-a60c-4b79-bd4c-385facb6dd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "sns.histplot(df.weight.apply(np.log), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1791e547-4b49-4a29-bd50-d286124dee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"species\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1fd4f0-bded-4490-abc2-6dd1ec516f56",
   "metadata": {},
   "source": [
    "### II. Feature - target split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83412d0-a8cb-4173-ba9c-8f05d6caca78",
   "metadata": {},
   "source": [
    "Suppose we want to predict the weight (in log space) of a fish. We will build a model with the remaining features as predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd37df9-c389-42e5-8c6d-e1d29d08943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the input features and the target variable\n",
    "X = df.drop(columns=\"weight\")\n",
    "y = np.log(df.weight) # predicting weight in log-scale\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12db2ba9-ca11-4524-b870-ed7acfe38dc3",
   "metadata": {},
   "source": [
    "### III. Train - test split\n",
    "Ideally you would split your data into train and test sets before modeling. <br>\n",
    "I'm doing a 70-30 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc83afe5-19c4-420b-9d12-621d9f16ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecb460e-9328-4a51-a8b9-678c705ed67a",
   "metadata": {},
   "source": [
    "### IV. Data pre-processing\n",
    "Then you would standardize the numeric columns and encode the categorical columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6e014d-25b6-42b1-8b86-bd992873838d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#1409FA\">Scaling Numerical data</span>\n",
    "Several machine learning algorithms rely on calculating distances. Therefore, it is important to have all the input features on the same scale - so that the distances computed for different features are comparable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbce36f-9468-45e0-a5fc-571722190668",
   "metadata": {},
   "source": [
    "#### <span style=\"color:teal\">Scaling features to a range</span>\n",
    "Apart from standardization, we can scale features to lie between a given minimum and maximum value, often between zero and one. Range compression helps with robustness due to small standard deviations of features after scaling and at the same time preserves zero entries.\n",
    "$$ x' = \\frac{x - min}{max - min} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b3d9ca-4310-42d9-848b-a51b2f0829a1",
   "metadata": {},
   "source": [
    "#### <span style=\"color:teal\">Standardization</span>\n",
    "This is the process of converting data into the standard format where each feature has zero mean and unit variance (i.e., std=1).\n",
    "$$ x' = \\frac{x - \\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479ce0f1",
   "metadata": {},
   "source": [
    "#### I. Find the fit parameters for standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64037385-5c9d-4533-a828-7b417eeba346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class \"StandardScaler\" from the scikit learn library\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e1910d-8fcc-4e1d-908f-044f3d18281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler is an object or instance of class StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84091d85-9d87-4e92-b0f7-16c1fa509963",
   "metadata": {},
   "source": [
    "Hover on the \"i\" icon - what does it say?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b31030-c7e0-44f2-ae63-b0f5f6aaa71a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now feed your data for pre-processing into this object\n",
    "scaler.fit(X_train)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd7c115-17fd-43f5-8d9d-0c40a086a0bd",
   "metadata": {},
   "source": [
    "What happened here? why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7579df95-3fd6-4169-a046-36ca1542a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the numeric columns\n",
    "numeric_cols = ['vertical_len', 'diag_len', 'cross_len', 'height', 'width']\n",
    "\n",
    "scaler.fit(X_train[numeric_cols])\n",
    "scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883f8f8c-b995-4d60-b842-b2917042f269",
   "metadata": {},
   "source": [
    "Hover on the \"i\" icon - what does it say now? <br>\n",
    "Once the data is fit, it means that the scaler has calculated the parameters for scaling i.e. the mean and the standard deviation, for each of the numeric columns. However, we still need to calculate the scaled (also called transformed) values (x prime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba73092d",
   "metadata": {},
   "source": [
    "$$ x' = \\frac{x - \\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb2deff-89b2-45f2-8303-2da93e852886",
   "metadata": {},
   "source": [
    "#### II. Transform the train AND test data with the fit paramaters you found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4219baa0-823e-45ac-803f-d9f745d7094f",
   "metadata": {},
   "source": [
    "Important note: preprocessing should be fit to train dataset, instead of applying to the whole set, to avoid leakage of information. Data leakage essentially means that the training process has information about, and thus will create a bias toward, the test set, potentially leading to a deceptively good generalization result.\n",
    "\n",
    "After the preprocessor learns to fit the train dataset, it is then used to transform the train and test set. More specifically, in the case of standardization,the preprocessor will obtain the mean and standard deviation of the train set and use those statistics to transform both the train and test set. As a result, after the transformation, the train set will definitely have 0 mean and unit standard deviation but the test set may not. Why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec19310c-bbd7-4afb-a2dd-dc86d76f1d37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the transformed X_train and X_test data\n",
    "numeric_X_train = scaler.transform(X_train[numeric_cols])\n",
    "numeric_X_test  = scaler.transform(X_test[numeric_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8931385-6471-47db-a5a4-65f5cf8c8451",
   "metadata": {},
   "source": [
    "Let's see what the transformed data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9466a83-195c-438f-96c1-97e10c73478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_X_train_df = pd.DataFrame(data = numeric_X_train, columns= numeric_cols)\n",
    "display(numeric_X_train_df.head(2))\n",
    "display(X_train[numeric_cols].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951cc07e-3ef8-4b31-81e1-8a5c8e078c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_X_train_df.describe().loc[\"mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb0fef-f1d7-45f2-8f0d-5abe22b56f04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T22:50:39.822671Z",
     "iopub.status.busy": "2024-04-21T22:50:39.822040Z",
     "iopub.status.idle": "2024-04-21T22:50:39.831642Z",
     "shell.execute_reply": "2024-04-21T22:50:39.830643Z",
     "shell.execute_reply.started": "2024-04-21T22:50:39.822636Z"
    }
   },
   "source": [
    "What do you notice about the mean of the transformed values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc431e4-44a5-4838-b77a-2927f49f71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_X_train_df.describe().loc[\"std\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b593988-0601-47ce-b5ff-8f0930f5c4ea",
   "metadata": {},
   "source": [
    "What do you notice about the standard deviation of the transformed values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06d62bd-55bb-4bbb-b289-8727da4616e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#1409FA\">Encoding Categorical data</span>\n",
    "Data sometimes come in non-numeric values in predictors and/or response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e2d86-6f39-4709-85d8-5af43ae0e8f5",
   "metadata": {},
   "source": [
    "#### <span style=\"color:teal\">Ordinal encoding</span>\n",
    "This is the process of assigning each unique category an integer value. Doing this, we impose a natural ordered relationship between each category.\n",
    "\n",
    "For example, age is ordered in nature and we can map the different ranges to integer values. More specifically, 30-39 => 0, 40-49 =>1, 50-59 => 2, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4ae901-3164-44f7-b49b-204319789252",
   "metadata": {},
   "source": [
    "#### <span style=\"color:teal\">One-hot encoding</span>\n",
    "When there is no natural ordinal relationship among different categories, OrdinalEncoder is not an appropriate approach.\n",
    "\n",
    "In addition, when the response variable has no ordinal relationship, encoding its labels as ordered integer values can result in poor performance. For example, suppose we encode the response's labels as 0, 1, 2. The algorithm can return a prediction of 1.5.\n",
    "\n",
    "One-hot encoding is the process of transforming each label of the orginal categorical variable into a new binary variable. This means the total number of features will increase after preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9223b93b-e84f-454f-95d6-28088799b828",
   "metadata": {},
   "source": [
    "#### I. Find the fit parameters for standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ecceee-66a1-4179-adc0-771ea98860ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class \"OneHotEncoder\" from the scikit learn library\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b2ed3-91ef-4332-a68b-7be5314834c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object/instance of class OneHotEncoder\n",
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837efeac-ddf7-40d7-88d0-3d3f5a0164da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now feed your categorical columns of train X for pre-processing into this object\n",
    "categorical_cols = ['species']\n",
    "\n",
    "ohe.fit(X_train[categorical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2ac0d3-7318-47bb-a0ed-f22bf6e30e2d",
   "metadata": {},
   "source": [
    "#### II. Transform the train AND test data with the fit paramaters you found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0573c4-6612-4a6a-8380-b18a641b7dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform both train and test\n",
    "ohe_X_train = ohe.transform(X_train[categorical_cols]) # transform train set\n",
    "ohe_X_test = ohe.transform(X_test[categorical_cols])   # transform test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237e99bc-9a22-4e95-8510-3400b600ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to an array\n",
    "ohe_X_train = ohe_X_train.toarray()\n",
    "ohe_X_test = ohe_X_test.toarray()\n",
    "\n",
    "ohe_X_train.shape, ohe_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8044c3-f860-4b0a-8c43-f7e4113fe0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- stack the processed columns together---------------\n",
    "processed_X_train = np.hstack((numeric_X_train, ohe_X_train))\n",
    "processed_X_test = np.hstack((numeric_X_test, ohe_X_test))\n",
    "\n",
    "processed_X_train.shape, processed_X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8633471c-33f5-4893-aef6-c9e63e069722",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-28T19:01:46.684797Z",
     "iopub.status.busy": "2024-04-28T19:01:46.684113Z",
     "iopub.status.idle": "2024-04-28T19:01:46.689129Z",
     "shell.execute_reply": "2024-04-28T19:01:46.688520Z",
     "shell.execute_reply.started": "2024-04-28T19:01:46.684753Z"
    }
   },
   "source": [
    "### <span style=\"color:#1409FA\">Putting it all together</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5ebb5a-e0ea-472e-9d09-454698a0ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['vertical_len', 'diag_len', 'cross_len', 'height', 'width']\n",
    "categorical_cols = ['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502ace20-6ce4-4a38-a0f3-82310940cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the numeric columns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()           # generate instance\n",
    "scaler.fit(X_train[numeric_cols])   # fit the scaler with train X\n",
    "\n",
    "# get the transformed X_train and X_test data\n",
    "numeric_X_train = scaler.transform(X_train[numeric_cols])\n",
    "numeric_X_test  = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "numeric_X_train.shape, numeric_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a6ba36-ef9e-479c-bf86-c6ad9f8b9b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the categorical columns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()               # generate instance\n",
    "ohe.fit(X_train[categorical_cols])  # fit the encoder with train X\n",
    "\n",
    "# get the transformed X_train and X_test data\n",
    "ohe_X_train = ohe.transform(X_train[categorical_cols]) # transform train set\n",
    "ohe_X_test = ohe.transform(X_test[categorical_cols])   # transform test set\n",
    "\n",
    "# convert to array\n",
    "ohe_X_train = ohe_X_train.toarray()\n",
    "ohe_X_test = ohe_X_test.toarray()\n",
    "\n",
    "ohe_X_train.shape, ohe_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea4071e-6818-4041-9bd1-8cfb1165f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use hstack to join the separately processed columns back together\n",
    "processed_X_train = np.hstack((numeric_X_train, ohe_X_train))\n",
    "processed_X_test = np.hstack((numeric_X_test, ohe_X_test))\n",
    "\n",
    "processed_X_train.shape, processed_X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3085adf-bf4f-4732-89fd-a39cb7808822",
   "metadata": {},
   "source": [
    "### V. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661cbe7d-bdd7-4cc7-8605-88d6e0d5dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression() # create an instance of class \"LinearRegression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f384f86-61d7-4236-aacc-9f80dd10534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to your data features and labels\n",
    "model.fit(processed_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9e53c4-9a26-40d5-aaeb-d81af09a0d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the model results\n",
    "model.intercept_, np.exp(model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162c93cb-8fd9-4122-a0d6-34759522c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2870b7-2acd-42f2-a48d-53564af88eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a263b338-c5a8-443c-8326-8bae7ec4488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = numeric_cols + list(ohe.categories_[0])\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d8405b-b4f5-4989-8bf8-0689f04e34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model coefficients inside a nice dataframe which includes the input feature names\n",
    "feature_names = numeric_cols + list(ohe.categories_[0])\n",
    "coefs = pd.DataFrame(data=model.coef_, \n",
    "                     columns=[\"Coefficients\"], \n",
    "                     index=feature_names,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5197c109-e7d7-47d5-b4be-c1d22f86a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18c5c72-6634-4c52-bf84-86f900ed40f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model coefficient\n",
    "coefs.plot.barh(figsize=(10, 4))\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.xlabel(\"Coefficient values\")\n",
    "plt.subplots_adjust(left=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3035398f-2ba7-4a35-8306-99037df70b18",
   "metadata": {},
   "source": [
    "From this plot, we would infer that the important factors in determining weight of a fish are: whether it is a smelt, and the vertical and diagnoal length of the fish. \n",
    "\n",
    "Comparing weight based on their magnitude to determine feature importance can be misleading if features vary widely, i.e., their variances/standard deviations are of different scale. However, we already standardize our dataset and eliminate this concern. Thus, it is relatively safe to make the inference above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196d35f7-45fe-4607-9476-b3d1d6436845",
   "metadata": {},
   "source": [
    "### VI. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af57a63d-4424-4627-8aa6-1e53ec5108dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_train = model.predict(processed_X_train)\n",
    "y_predicted_test = model.predict(processed_X_test)\n",
    "\n",
    "y_predicted_train.shape, y_predicted_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23cb5d4-32eb-43f4-9bb5-7d28432df929",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b39c24-e8bc-484f-8aa6-01be81a962e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's compare our predicted weights to the observed weights\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,3))\n",
    "\n",
    "axes[0].scatter(y_train, y_predicted_train, s=2)\n",
    "axes[0].set_title(\"Train data\")\n",
    "axes[1].scatter(y_test, y_predicted_test, s=2)\n",
    "axes[1].set_title(\"Test data\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\"red\")\n",
    "    ax.set(xlabel=\"Observed weight\", ylabel=\"Predicted weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc028fdf-8517-4cb7-9c12-6d37729e7d19",
   "metadata": {},
   "source": [
    "### VII. Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7696bb2f-566c-4b7c-b4f6-b71b7b5b5dc9",
   "metadata": {},
   "source": [
    "We are interested in understanding how well the learned model generalizes. There are several metrics to quantify the quality of a model.\n",
    "\n",
    "A typical measure for regression is the mean squared error\n",
    "$$\n",
    "MSE = \\frac{1}{M} (y_{pred} - y_{obs})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd5bd9-3c7f-48d3-b647-1addde303335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a159383b-0f25-4da8-88aa-a10ab6534d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_predicted_test)\n",
    "print(\"test MSE - \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1fd46-7b88-4edf-9d5c-a1bb283da0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_train, y_predicted_train)\n",
    "print(\"train MSE - \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57609927-77a8-41fc-a05f-e461ab67aac3",
   "metadata": {},
   "source": [
    "Another measure is $R^2$ score, which indicates a goodness of fit. More specifically, it represents the proportion of the response's variance that has been explained by the predictors. Best possible score is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6708e5b3-eccf-4a81-87de-bd8c05dea1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6155b36a-3c26-4af9-92aa-cc92231dc01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_predicted_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa612bd1-858c-40bc-a4f2-b71056831a41",
   "metadata": {},
   "source": [
    "<span style=\"color:#DC537D\"><font size=\"+1\">Does it matter if train error is much smaller than test error? Why or why not?</font></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ad665d-c17f-4dd5-bbee-fe6a2d08fe14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31b031-9bd2-4d81-8564-d06a0757f01d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
