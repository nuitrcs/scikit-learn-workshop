{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "855e6e11-389a-4edb-9b32-eef018d04f17",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:crimson\">Supervised ML with scikit-learn</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7693eaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:rebeccapurple\">Setup</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f1237-f931-4272-aa29-d667d8a41631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dabb9d1-a429-4832-b56e-266cb4b46904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting some figure display paramaters\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white', {'axes.linewidth': 0.5})\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['xtick.major.size'] = 3\n",
    "plt.rcParams['xtick.major.width'] = 1\n",
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['ytick.left'] = True\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['legend.edgecolor'] = 'w'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e58f58b-49a0-4790-9af3-cd76ae43e1cf",
   "metadata": {},
   "source": [
    "## <span style=\"color:rebeccapurple\">Classification with kNN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cc9313-7ed5-4664-ae75-d0cfd92f022f",
   "metadata": {},
   "source": [
    "* kNN, or the k-nearest neighbor algorithm, is a machine learning algorithm that uses proximity (or distance) to compare one data point with a set of data it was trained on and has memorized to make predictions.\n",
    "* 'k' represents the number of nearest neighbors considered in the classification or regression problem, and 'NN' stands for the nearest neighbors to the number chosen for k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7788e7-55c0-4ff2-8acb-0df19884bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image('images/knn_image.png', width=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc461544-11ae-4f6b-8698-e8463c8f9d78",
   "metadata": {},
   "source": [
    "In the schematic above, an unknown data point (red) will be classified as either class A (yellow) or class B (purple) depending on who its nearest neighbors are in the feature space [x1, x2] , and how many nearest neighbors we choose to use for our estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f21bdc4-ea5b-497c-8e75-7004ae9522ea",
   "metadata": {},
   "source": [
    "<b>Let's use kNN to classify wines!</b> <br>\n",
    "The data is the results of a chemical analysis of wines grown in the same region in Italy by three different cultivators. There are thirteen different measurements taken for different constituents found in the three types of wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c38bc-817e-4649-a163-c4e8989233e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "wine = datasets.load_wine()\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "df['label'] = wine.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141a588d-7a4f-4e00-a025-6236948edccd",
   "metadata": {},
   "source": [
    "### I. Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6baf938-f8f6-4c19-8807-a8b5cb88a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb25d58-c062-4575-b3cb-853fb94b3de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "sns.countplot(df, x=\"label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f43b4b0-e9bf-45b1-98dd-4c3f80407b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"label\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67a0153-76a6-4627-87a1-30bec9b4aea0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T12:10:00.769202Z",
     "iopub.status.busy": "2024-06-26T12:10:00.768520Z",
     "iopub.status.idle": "2024-06-26T12:10:00.776964Z",
     "shell.execute_reply": "2024-06-26T12:10:00.775345Z",
     "shell.execute_reply.started": "2024-06-26T12:10:00.769169Z"
    }
   },
   "source": [
    "We see from above that some features might be more helpful in the classification than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2263f-16a8-4d84-8593-c49f3cc7cb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(df.iloc[:,:-1].corr(), annot=True, cmap=\"YlGnBu\", square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17659478-51a2-4e19-8d5e-3389bac12cc0",
   "metadata": {},
   "source": [
    "Some features seem to be well-correlated with each other. This information can help us decide if we want to reduce the dimensionality of a dataset since highly correlated features carry the same information, and keeping all of them may not be useful.\n",
    "However, remember there are 3 classes of wine in the dataset, and the correlation matrix might look different for the classes individually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683f4e40-f9c7-45bb-b244-713e1fc887bf",
   "metadata": {},
   "source": [
    "### II. Feature - target split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabdae57-cc41-4e6a-9e69-b205071cafea",
   "metadata": {},
   "source": [
    "We want to predict which cultivator a wine originates from based on the chemical composition of the wine. Therefore, the chemical measurements will be our features or predictors to predict the label/origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7d4a76-bccf-4fc2-ab10-cb884aa16550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the input features and the target variable\n",
    "X = df.drop(columns=\"label\")\n",
    "y = df.label\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0233673d-c3ff-4288-bbb7-260a55f8bbc9",
   "metadata": {},
   "source": [
    "### III. Building a kNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ba41d-ee32-42f4-8b10-0282bf6e0fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model class from sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fa9dff-b32b-4b85-80c6-63e685aa947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the class object\n",
    "model = KNeighborsClassifier(n_neighbors=3) # choosing the value of k to be 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4a523d-052f-42ec-bc06-83b639b72873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model with the X and y data\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e276e-6743-4495-801e-69ab3ee3e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the classes\n",
    "model.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b27b4b3-94dd-4a53-b0ae-a733b7dc3dd6",
   "metadata": {},
   "source": [
    "However, what will we predict on - we used all our available data to train the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74527698-6bdc-4d52-8fc7-7f3c86f4e76d",
   "metadata": {},
   "source": [
    "### IV. Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d3164d-ba41-4900-a516-d5d59def1647",
   "metadata": {},
   "source": [
    "In order to build a model based on the available data, we would need to keep some portion of it \"unseen\" so that we can assess how well the trained model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329a1118-5c99-4fa4-9a3c-7d410fc5ddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e94ded2-e385-4198-ad8e-afc635ac3c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data 70-30, and ensure labels are distributed proportionately between train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,           # features, labels\n",
    "                                                    test_size=0.3,  # fraction of data as test\n",
    "                                                    stratify=y,     # stratification of data by y\n",
    "                                                    random_state=42)# seed parameter -- optional\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618480c2-993e-4545-ad0c-af9a3a00c69f",
   "metadata": {},
   "source": [
    "### <span style=\"color:crimson\">Exercise</span>\n",
    "Re-build the kNN model from above, but only using the training data to fit the model this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b6485e-ca78-494c-865c-cce011275286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model object of class KNeighborsClassifier with k=3\n",
    "model = ___(___ = ___)\n",
    "\n",
    "# fit the model to the training data\n",
    "model.___(___ , ___)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d7b780-fa99-4b04-b6e8-7137f36b27a2",
   "metadata": {},
   "source": [
    "Now that we have our fitted model, let's look at how well it can predict unseen data-points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb6dc36-258e-47fd-b667-6ab2bad6690d",
   "metadata": {},
   "source": [
    "### IV. Generating predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3bc6a2-33c5-4bff-bf9a-36d30aa450ef",
   "metadata": {},
   "source": [
    "We will generate predicted labels for each observation in the test data. Then we will compare the predicted labels to the actual/observed labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e501211-5249-494f-a445-7b2dc6231308",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e3a3d-777f-4871-9b93-126df94ded9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the predicted labels in y_pred \n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af78cba5-50aa-41c0-b404-6817335f8ecc",
   "metadata": {},
   "source": [
    "We can also generate predicted probabilities for each class (the class with the highest probability for a given observation is chosen as the predicted \"label\" above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6801a982-53eb-4947-b9c9-6193c11931a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43123d72-a219-4f25-9227-50996aeb7709",
   "metadata": {},
   "source": [
    "Probabilities are helpful to decide thresholds of classification.\n",
    "\n",
    "For example, in a binary classification problem with only 2 labels, by default a probability value 0.5 is used as a threshold. Therefore, if the probability for class 1 is equal to or greater than 0.5, it will be classified as a \"positive\" (or whatever the label is). But sometimes, you get better model performance when the threshold is adjusted up or down.\n",
    "\n",
    "In multi-class classification (as in our wine dataset with 3 classes), the class with the highest predicted probability is chosen as the predicted label for each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646cdfa1-f6c1-4386-bd72-35eb73471b92",
   "metadata": {},
   "source": [
    "### V. Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae7f21a-0565-4f79-a0b0-d803b80ac857",
   "metadata": {},
   "source": [
    "There are several ways to evaluate classification models. For now, let's look at the model accuracy i.e. how many times did the model predict the label correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d71c4b-8cb2-4522-a80f-95543483076a",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e3ffc-164e-4364-8ebd-1d2cf02827bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa26f61-8463-4663-97d3-3b1ad6943a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what fraction of samples were correctly predicted\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a40c0-b3e6-4ef6-a77c-7527aa3b2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting normalize=False gives us the number of correctly predicted samples\n",
    "accuracy_score(y_test, y_pred, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6f62e0-dde8-42ee-94c7-7f12a734ecb1",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2209c7-57c5-4695-97e4-289a66bd03c8",
   "metadata": {},
   "source": [
    "You can also build a text report showing the main classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1878aa06-5800-4817-9bd5-d603937df691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d564a4a1-8c57-42ed-ac3c-e67ec33ae221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_report(y_true, y_pred, target_names)\n",
    "\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b3c1cf-d236-4da0-ad85-0a7d625de179",
   "metadata": {},
   "source": [
    "The method of evaluation depends on the user. For example, perhaps it is more important for  me to make sure I catch all the true positives for cancer in a cancer diagnosis dataset. If 95% of samples are cancer-negative in a general population, then predicting \"negative\" for every sample without any learning will still give me a 95% accuracy rate!\n",
    "\n",
    "The above example is also a problem of what is called<b> \"class imbalance\"</b>. Not controlling for class imabalances will give you falsely high accuracy rates. There are ways to deal with this, for example by setting \"weights\" for each class to balance them. This is similar to over-sampling or under-sampling a particular class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0247fad-3f71-462f-b96d-e62ed5812dbc",
   "metadata": {},
   "source": [
    "#### AUROC (for 2 classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf17bca-78bf-4c2d-9d64-ba5871101949",
   "metadata": {},
   "source": [
    "A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the performance of a binary classifier model at varying threshold values. The ROC curve is the plot of the true positive rate against the false positive rate at each threshold setting.\n",
    "\n",
    "AUROC or Area under the ROC is a performance metric for “discrimination”: it tells you about the model’s ability to discriminate between cases (positive examples) and non-cases (negative examples.) An AUROC of 0.8 means that the model has good discriminatory ability: 80% of the time, the model will correctly assign a higher absolute risk to a randomly selected patient with an event than to a randomly selected patient without an event.\n",
    "\n",
    "The AUROC is more informative than accuracy for imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb0601-8a9a-4658-97d6-98900dfede98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image('images/roc_curve.png', width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dccce16-3b7d-48b4-bd51-187b6b3995dd",
   "metadata": {},
   "source": [
    "The worst AUROC is 0.5, and the best AUROC is 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9301bb0-5dcc-4948-a60a-8ed622dfff3d",
   "metadata": {},
   "source": [
    "Let's see an example using a breast cancer dataset where samples are classified as either malignant or benign based on morphological features of the cell nuclei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2cfb70-7f97-424d-b8be-9b24176e4098",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = datasets.load_breast_cancer()\n",
    "\n",
    "# create dataframe\n",
    "breast_cancer_df = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "breast_cancer_df['label'] = breast_cancer.target\n",
    "\n",
    "display(breast_cancer_df.head())\n",
    "\n",
    "print(breast_cancer_df.shape)\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "sns.countplot(breast_cancer_df, x=\"label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8bcab1-854e-4bbe-8cfc-0cb4f406744a",
   "metadata": {},
   "source": [
    "You can see above that the classes are imbalanced - there are many more benign (class 1) samples in the dataset than malignant (class 0) samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcebf7a-384b-40ca-b1b0-d68368732253",
   "metadata": {},
   "source": [
    "Below we build a kNN classification model and plot the AUROC curve for different values of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6234f3b5-4444-404d-b8ee-836ef20a16be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auroc_breast_cancer_data(k):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    \n",
    "    # build kNN model fit to classify malignant [class 0] or benign [class 1] samples\n",
    "    X = breast_cancer_df.drop(columns='label')\n",
    "    y = breast_cancer_df.label\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train,y_train)\n",
    "\n",
    "    # model evaluation\n",
    "    y_scores = knn.predict_proba(X_test)\n",
    "    fpr, tpr, threshold = roc_curve(y_test, y_scores[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # plot ROC curve\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.title(f'ROC Curve of kNN, k={k}')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82992541-d53a-499e-aaee-7bd74e58ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_auroc_breast_cancer_data(k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb81d7e2-9592-49e0-bd1d-047d3010583b",
   "metadata": {},
   "source": [
    "### <span style=\"color:crimson\">Exercise</span>\n",
    "Generate ROC curves and look at the AUC value for k=1, and k=100.<br>\n",
    "Which one is the better classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461cc0ce-3508-4b0d-ac43-ceb2aae739a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220de4b4-211a-4dca-a97e-79f4b87b1918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f258dcb0-383f-4ca8-8627-68d197e129cc",
   "metadata": {},
   "source": [
    "Note though, you cannot always acheive an AUROC of 1.0 - that would mean perfect classification! The goal is usually to get a model that performs above 0.5, with typically 0.7-0.9 considered as good performance. The performance also depends on the data - if the data is complex or noisy, acheiving high performance is difficult or impossible sometimes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cffbc1-8fdd-4352-aba1-60bb6d6a74e0",
   "metadata": {},
   "source": [
    "### VI. Model optimization\n",
    "Can we make our wine classification kNN model even more accurate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd04aec1-7eed-4b73-aff4-bea1165a23d2",
   "metadata": {},
   "source": [
    "We used the parameter `n_neighbors` to set the value of k. We arbitrarily chose 3 neighbors, but how do we know this was the correct choice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80bfe58-594d-496e-9b37-aef6e0803e1d",
   "metadata": {},
   "source": [
    "One way to understand if there is room for improvement is to see how well the model works for the data on which it was trained vs the unseen test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599b65b6-60df-4f64-a8a0-1714ddcfc7b6",
   "metadata": {},
   "source": [
    "### <span style=\"color:crimson\">Exercise</span>\n",
    "We used the training data to teach the model how to learn. Let's see how well it learnt the training data itself. In an ideal scenario, the model should be 100% accurate on the training samples.\n",
    "\n",
    "Generate predictions for the training dataset, and get model accuracy for the training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ed9d1-1d78-4c60-8cbe-5c7a8861e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d86cc4-ba4a-4106-b97b-085c008d068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(___ , ___)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73acaf2-e330-4834-98df-5636890209a5",
   "metadata": {},
   "source": [
    "We see that our model predicts much better on the data on which it was trained, compared to unseen data! This means that there is space for improvement. Ideally you want to get the model optimized such that it performs equally well (or as closely matched as possible) for the train and the test set.\n",
    "\n",
    "This is because we want the model to generalize well to unseen samples rather than over-fitting to the samples in the training data. Consider that if we were to generate a different train-test split, we would get a completely different model if it was over-fitted to the samples in each train set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302b5607-a596-4680-89c4-54b279b51c15",
   "metadata": {},
   "source": [
    "<b> Creating a performance optimization curve </b> <br>\n",
    "In order to choose the best value of k (on `n_neighbors`) we must build models with several different values of k, and compare their train and test accuracy. The parameter value at which train and test data sets perform equally well is usually the sweet-spot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e091621d-a493-4f97-b6cb-9b0741473f3e",
   "metadata": {},
   "source": [
    "### <span style=\"color:crimson\">Exercise</span>\n",
    "Generate a performance curve for different values of k neighbors, and decide which is the best value of k to choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb62609-afb6-47b1-a479-5aefbd6d5eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup arrays to store train and test accuracies\n",
    "neighbors = np.arange(1, 25)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "# Loop over different values of k\n",
    "for i, k in enumerate(neighbors):\n",
    "    # Setup a k-NN Classifier with k neighbors\n",
    "    model = KNeighborsClassifier(n_neighbors = k)\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    model.___(___ , ____)\n",
    "\n",
    "    # Compute the accuracy on the training set\n",
    "    y_train_pred = ______\n",
    "    train_accuracy[i] = ___(___ , ____)\n",
    "\n",
    "    # Compute the accuracy on the test set\n",
    "    y_test_pred = ______\n",
    "    test_accuracy[i] = ___(___ , ____)\n",
    "\n",
    "\n",
    "# Generate plot\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.title('k-NN: Varying Number of Neighbors')\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc12851-c10f-4aa7-9b87-c3aed25bc9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8219451c-d2fc-4437-9325-d3f3eaec3b78",
   "metadata": {},
   "source": [
    "What do you observe? \n",
    "\n",
    "Which is the best value of k neighbors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d2344d-5248-4e9d-b12c-42e9e02c72af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T13:03:07.595320Z",
     "iopub.status.busy": "2024-06-26T13:03:07.594717Z",
     "iopub.status.idle": "2024-06-26T13:03:07.615439Z",
     "shell.execute_reply": "2024-06-26T13:03:07.614447Z",
     "shell.execute_reply.started": "2024-06-26T13:03:07.595286Z"
    }
   },
   "source": [
    "Notice in the plot above that choosing k=1 would give you near-perfect classification accuracy on the training data - this is a case of over-fitting to the training data. And this over-fitted model does not give us the best possible accuracy on the testing/unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af07b8-8f75-408e-8c04-ae089d896573",
   "metadata": {},
   "source": [
    "### VII. Detour: Model Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f28ece-5676-4e13-a565-8f79a22e5ba7",
   "metadata": {},
   "source": [
    "* Model complexity refers is a measure of how well a model can capture the underlying patterns in the data. In the context of machine learning, model complexity is often associated with the number of parameters in a model and its ability to fit both the training data and generalize to new, unseen data.\n",
    "  \n",
    "* Simple models have few parameters, making them less flexible therefore they struggle to capture the complexity of the underlying patterns in the data leading to underfitting, where the model performs poorly on the training data as well as on unseen data.\n",
    "  \n",
    "* Complex models have a larger number of parameters, allowing them to represent more intricate relationships in the data. While complex models may perform well on the training data, model tends to overfitting.\n",
    "Modelling complexity can be influenced by several factors:\n",
    "\n",
    "* Number of Features: The more attributes or features your model scrutinizes, the higher its complexity is likely to be. Too many features can potentially magnify noise and result in overfitting.\n",
    "\n",
    "* Model Algorithm: The nature of the algorithm used influences the complexity of the model. For instance, decision trees are considerably simpler than neural networks.\n",
    "\n",
    "* Hyperparameters: Settings such as the learning rate, number of hidden layers, and regularization parameters can influence the complexity of a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f70e75-32af-44eb-947b-c6f9d263b629",
   "metadata": {},
   "source": [
    "#### Why Model Complexity is Important?\n",
    "Finding the optimal model complexity is important because:\n",
    "\n",
    "* <b>Bias-Variance Tradeoff:</b> Model complexity is closely related to the bias-variance tradeoff. Simple models may have high bias (systematic errors), while complex models may have high variance (sensitivity to small fluctuations in the training data). Finding the right level of complexity involves managing this tradeoff to achieve good predictive performance.\n",
    "  \n",
    "* <b>Computational Resources:</b> Complex models often require more computational resources for training and inference. The choice of model complexity may be influenced by practical considerations such as available computing power and time constraints.\n",
    "  \n",
    "* <b>Interpretability:</b> Simple models are often more interpretable, making it easier to understand and explain their decision-making processes. In some cases, interpretability is crucial, especially in sensitive applications where decisions impact individuals’ lives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18cb0d5-a590-41b7-84ef-963471fd4e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image('images/bias_variance.png', width=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ede53-3db5-4739-98a2-c5db276a352c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image('images/linear_model_bv.png', width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c8261b-11c5-4376-8743-3334b9d7cc9a",
   "metadata": {},
   "source": [
    "#### What is Model Overfitting?\n",
    "\n",
    "Overfitting happens when a machine learning model gets trained too well on the so-called training data. While it may sound like a good thing, in reality, an overfitted model performs poorly when it encounters new, unseen data since it’s considered too tuned to the training set. A good model should generalize well, not just perform well with the training data, but with new data as well.\n",
    "\n",
    "The concept of model overfitting is closely tied to model complexity. When a model is too complex, it has the capacity to fit the training data very closely, capturing even the smallest variations and fluctuations. While this may result in high accuracy on the training set, the model becomes excessively tailored to the specific characteristics of that data.\n",
    "\n",
    "As a consequence, the model struggles to generalize to diverse data points outside the training set, exhibiting poor performance on new data. In essence, overfitting is often a consequence of excessive model complexity, highlighting the importance of finding the right balance between simplicity and complexity to ensure robust generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d184b3-1e5e-4f81-bcec-509f1e15bc9a",
   "metadata": {},
   "source": [
    "#### How to Avoid Model Complexity and Overfitting?\n",
    "\n",
    "Addressing model complexity and overfitting is critical to achieving robust machine learning models. Here are some strategies:\n",
    "* <b>Split the dataset into training and testing Data:</b> Splitting your dataset is crucial because it ensures the model doesn’t simply memorize the training data and can generalize to unseen examples.\n",
    "\n",
    "* <b>Reducing Features:</b> By minimizing the number of input features, we could lower the complexity, and thus, prevent overfitting. Essentially, we would only keep the important or relevant features for classification, and discard the rest.\n",
    "\n",
    "* <b>Cross-validation:</b> Cross-Validation is a technique that assesses model generalization and provides a realistic measure of how well the model is likely to perform on unseen data, helping to assess its level of complexity and overfitting. Essentially it involves creating several train-test splits instead of just one split, and then using all these splits to fit a better, more generalized model. (But beware of data leakage!! - we will see how to do this properly)\n",
    "\n",
    "* <b>Regularization:</b> Regularization techniques introduce penalties for complexity in the loss function of the model which discourages learning overly complex model parameters, discouraging overfitting. L1 and L2 regularization are common methods to control the magnitude of coefficients, preventing the model from becoming overly complex.\n",
    "    \n",
    "* <b>Use of Ensemble Models:</b> Combining predictions from multiple diverse models can often lead to better performance and reduced risk of overfitting compared to relying on a single model. This is because individual models may have unique strengths and weaknesses, and averaging their predictions can lead to a more robust and generalizable result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8039db-121b-4640-a194-8eed761041c7",
   "metadata": {},
   "source": [
    "#### Decision boundaries and model complexity\n",
    "A decision boundary is a surface that separates two or more classes into different sets, where all the points belonging to one class lie on one side of the decision boundary. Let's see what that looks like for a toy dataset called `iris`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db64b555-431b-427e-8686-fbdbea13a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d00824-5300-4c4c-a1b7-2b9e06fdce30",
   "metadata": {},
   "source": [
    "To make the decision boundary easier to visualize we will assume the dataset has only 2 features, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db169bf-cac3-4827-a29f-50b0e9313ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = iris_df[['sepal length (cm)',\t'sepal width (cm)', 'label']]\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1311461b-7ecf-45f2-9444-46ad463f060b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cc9a7b-3c81-43dd-b05c-c2790243e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iris_decision_boundary(n_neighbors):\n",
    "    from matplotlib.colors import ListedColormap\n",
    "\n",
    "    # convert to numpy array for plotting a mesh plot\n",
    "    X = np.array(iris_df.drop(columns='label'))\n",
    "    y = np.array(iris_df.label)\n",
    "    \n",
    "    h = .02  # step size in the mesh\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF']) # color maps\n",
    "    cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "    \n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    clf = KNeighborsClassifier(n_neighbors)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, s=0.5)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title(\"kNN classification (k = %i)\"% (n_neighbors))\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc333730-5d99-4de5-ad58-b87307b5f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iris_decision_boundary(n_neighbors=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f3bea-c86a-4e90-b079-9698c62ca3ad",
   "metadata": {},
   "source": [
    "A real-world dataset usually has many features, and therefore the decision boundary is usually a hyperplane or hypersurface in N-dimensional feature space.\n",
    "\n",
    "A simple model might have linear or simple decision boundaries, while a complex model might have non-linear convoluted decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240d5356-261b-4ea4-a2d0-6b2f981727f8",
   "metadata": {},
   "source": [
    "### <span style=\"color:crimson\">Exercise</span>\n",
    "Use the `plot_iris_decision_boundary` function to plot what the classification boundaries look like for models built with different `n_neighbors` (k) values for the iris dataset which has 150 total observations. The function takes only one input which is the k value.\n",
    "\n",
    "Choose different values of k between 1-150 to see how the classification model changes. Does it become more or less sensitive to individual data-points as k increases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2444b85f-3ddd-4982-a16c-731f8952d1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343398b0-c7f7-4b1b-b04c-664a3cfe6bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46396ebb-6e85-4732-9997-8e3096092a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b069421-0f6a-4962-b820-a3e5598412b9",
   "metadata": {},
   "source": [
    "### VIII. Back to Model Optimization: Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a128bf6-9137-4623-9127-c8f5607b1e31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T13:26:17.606848Z",
     "iopub.status.busy": "2024-06-27T13:26:17.605856Z",
     "iopub.status.idle": "2024-06-27T13:26:17.615479Z",
     "shell.execute_reply": "2024-06-27T13:26:17.614052Z",
     "shell.execute_reply.started": "2024-06-27T13:26:17.606773Z"
    }
   },
   "source": [
    "Can we make our kNN model even better??<br>\n",
    "Let's take a re-look at our dataset features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab76c25-c032-4848-9038-b5635e871a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().loc[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4085d76-6b5c-497c-a74c-a47f4e3d09b5",
   "metadata": {},
   "source": [
    "The numerical ranges and values of the different features of the data have extremely different ranges, from ~1000 for proline to ~0.5 for nonflavonoid_phenols.\n",
    "\n",
    "Recall that kNN calculates the distance in feature space between observations. If we assume that distance refers to Euclidean distance (it doesn't have to), it would look as follows:\n",
    "$$\\begin{align}\n",
    "d = \\sum_{i=1}^N \\sqrt {\\left( {f_{i1} - f_{i2} } \\right)^2 }\n",
    "\\end{align}$$\n",
    "where $f_{i1}$ refers to the $i$th feature of data-point 1 and $f_{i2}$ refers to the $i$th feature of data-point 2. Therefore, we calculate the distance between 2 points on every feature dimension/axis, sum them up and then take the square root of the sum.\n",
    "\n",
    "If the scales in which the individual feautures are measured are vastly different, then the distance calculation will be much more sensitive to large feature values (such as proline) but not to small feature values (such as nonflavonoid_phenols).\n",
    "\n",
    "This will affect the calculation of the \"nearest neighbor\" in Euclidean space. For example, a 10% change in the value of nonflavanoid_phenols from $0.36$ to $0.39$ will be much less important that a 10% change in the value of proline from $746$ to $820$ i.e. features on large numerical scales will be default be considered \"more important\" than features on smaller numerical scales!\n",
    "\n",
    "A different way to think about this is consider if my feature space is height and weight of individuals to predict/classify for liekleihood of diabetes. If I meaure the height in m and weight in kgs it will be different that measuring the height in cm and weight in kg. Simply changing the scale will change the importance of the height metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befcb367-f751-4de2-a34a-519432a87d74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T13:45:56.141307Z",
     "iopub.status.busy": "2024-06-27T13:45:56.140453Z",
     "iopub.status.idle": "2024-06-27T13:45:56.148633Z",
     "shell.execute_reply": "2024-06-27T13:45:56.147525Z",
     "shell.execute_reply.started": "2024-06-27T13:45:56.141224Z"
    }
   },
   "source": [
    "#### Centering and scaling\n",
    "In order to make the measurements scale-independent, we can modify the features such that they are all on the same scale and therefore all equally important for the distance calculation. A popular way of doing this is centering and scaling (also called feature standardization)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55527e78-0719-4366-a99d-c9b1aa3697c1",
   "metadata": {},
   "source": [
    "#### <span style=\"color:teal\">Standardization</span>\n",
    "This is the process of converting data into the standard format where each feature has zero mean and unit variance (i.e., std=1).\n",
    "$$ x' = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "We can do this easily with sklearn --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacd7e06-1119-4254-952e-884730bd57d9",
   "metadata": {},
   "source": [
    "##### a) Find the fit parameters for standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c685687-d203-4db8-98ad-9536a0891ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class \"StandardScaler\" from the scikit learn library\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950f58e9-ae4e-4b30-bfae-00057bd79858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler is an object or instance of class StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17771da-f93f-41da-8616-b1d904f1c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now feed your feature data X for pre-processing into this object\n",
    "X = df.drop(columns='label')\n",
    "scaler.fit(X)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02df934b-cafe-4bd8-8291-6b18b5a4d1bb",
   "metadata": {},
   "source": [
    "Hover on the \"i\" icon - what does it say now? <br>\n",
    "Once the data is fit, it means that the scaler has calculated the parameters for scaling i.e. the mean and the standard deviation, for each of the numeric columns. However, we still need to calculate the scaled (also called transformed) values ($x'$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097f618f-097b-409a-8551-71cc638ed5c3",
   "metadata": {},
   "source": [
    "##### b) Transform the data with the fit paramaters you found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4e58e4-732b-4156-82e0-360f38720b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e276f-5d97-45ef-8946-d7cf0ada89f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to a dataframe to view\n",
    "scaled_X_df = pd.DataFrame(data = scaled_X, columns= X.columns)\n",
    "\n",
    "\n",
    "print('---- scaled mean-----')\n",
    "print(scaled_X_df.describe().loc['mean'])\n",
    "print('\\n---- scaled std-----')\n",
    "print(scaled_X_df.describe().loc['std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a384d40e-4a1b-4fa3-8f6f-2a02e75dddbc",
   "metadata": {},
   "source": [
    "What do you notice about the mean and standard deviation of the transformed values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae324506-97d7-4eee-9c63-86b512142a8d",
   "metadata": {},
   "source": [
    "Let's see scaling affects model performance or accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c683d3-826e-4b68-95fd-e0094fd02c4f",
   "metadata": {},
   "source": [
    "### IX. Creating a better model with feature scaling\n",
    "Now that we know how to do this, we should go back and scale our train and test data before fitting and evaluating our kNN model. \n",
    "\n",
    "It is critical to treat the test and train sets <b>independently</b> instead of scaling the whole dataset at once. This is done to avoid data leakage i.e. unintentionally exposing our test data set to the model. Since the model never sees the test data, the model should only learn the scaling fit parameters from the train data. However, once the model learns the scaling fit parameters, both the train and test sets can be transformed with these learned values.\n",
    "\n",
    "### <span style=\"color:crimson\">Exercise</span>\n",
    "Can you guess why scaling <i>before</i> splitting the data might lead to data leakage?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f684f18a-bf7d-4d2a-982a-79da0d062119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T14:03:18.487405Z",
     "iopub.status.busy": "2024-06-27T14:03:18.486710Z",
     "iopub.status.idle": "2024-06-27T14:03:18.494737Z",
     "shell.execute_reply": "2024-06-27T14:03:18.493530Z",
     "shell.execute_reply.started": "2024-06-27T14:03:18.487360Z"
    }
   },
   "source": [
    "### <span style=\"color:crimson\">Exercise</span>\n",
    "<b>Putting it all together</b><br>\n",
    "Rebuild the kNN model with feature scaling, and test for best k values by generating a performance curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069b964b-96f3-4cc9-b7ad-c75a344a4f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the dataset to start afresh\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "df['label'] = wine.target\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b548da-7ddd-44ba-8c47-0d6a54882dd3",
   "metadata": {},
   "source": [
    "#### Step 1: Feature - Target split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd6372-b647-4c28-820f-aed600b7def0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the input features and the target variable\n",
    "X = ______\n",
    "y = ______\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ee68b7-db84-447e-a5d9-30ee34f33957",
   "metadata": {},
   "source": [
    "#### Step 2: Train - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c5e94-49b5-4827-a6f7-a07abb9fd7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn._______ import ________\n",
    "\n",
    "# split the data 70-30, with 30% in the test set\n",
    "# Make sure the label classes are evenly distributed between the train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(___ ,____ , \n",
    "                                                    test_size=_____,\n",
    "                                                    stratify=___,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0a7094-becb-4932-a0b1-2c44f0531d3d",
   "metadata": {},
   "source": [
    "#### Step 3: Data pre-processing with feature scaling\n",
    "Remember, scale the training data only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c444e3af-20d9-4a9f-a024-7c4c8d9653ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import ___________\n",
    "\n",
    "scaler = ______\n",
    "scaler._____(____)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8765bc4-2319-4e9c-98b5-4ce991aa7b0a",
   "metadata": {},
   "source": [
    "Transform both the train and test X with the learned scaling fit parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b6605-976b-43a5-9625-e61e492f04a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = _____._____()\n",
    "scaled_X_test = _____._____()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646f92e1-461a-4f26-a7dc-23c93e522280",
   "metadata": {},
   "source": [
    "#### Step 3: (kNN) Model building and optimization for best accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85685f0-5c2d-4bf3-9989-9fcd21ac6112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import _________\n",
    "from sklearn.metrics import ___________\n",
    "\n",
    "# Setup arrays to store train and test accuracies\n",
    "neighbors = np.arange(__ , ___)  #<------ choose any range you like (within reason)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "# Loop over different values of k and calculate accuracy\n",
    "for i, k in enumerate(neighbors):\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors = k)\n",
    "\n",
    "    # Fit the classifier to the scaled training data\n",
    "    model.___(___ , ____)\n",
    "\n",
    "    # Compute the accuracy on the scaled training set\n",
    "    y_train_pred = ______\n",
    "    train_accuracy[i] = ___(___ , ____)\n",
    "\n",
    "    # Compute the accuracy on the scaled test set\n",
    "    y_test_pred = ______\n",
    "    test_accuracy[i] = ___(___ , ____)\n",
    "\n",
    "\n",
    "# Plot the model performance curve\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.title('k-NN: Varying Number of Neighbors')\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de03c9cc-aa82-4e72-965c-00667eb1cb3e",
   "metadata": {},
   "source": [
    "What do you observe about model accuracy scores comparing between scaling vs not scaling the features before modeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d392a210-356a-4819-8dbd-cdb26c6b98f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0b3244-8cf0-42cc-9d4a-fdeed079c28f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
